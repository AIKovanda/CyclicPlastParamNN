tasks: rcpl.tasks.processing.*
uses: "{CONFIGS_DIR}/dataset/maftr/2023-11-23.d1.maftr6_4.yaml"

model:
  class: rcpl.models.gru.GRU
  kwargs:
    batchnorm: true
    in_channels: 1
    layers: 6
    hidden_size: 128
    outputs: 16
    rnn_kwargs:
      bidirectional: true
    first_last: true

takes_max_length: 681
takes_channels: ['stress']
do_compile: true
is_trainable: true
prediction_is_scaled: true
# chosen_checkpoint: 199


persistent_training_params:
  epochs: 10

  optim: 'AdamW'
  optim_kwargs:
    lr: 0.001
    weight_decay: 0.01

  dataloader_kwargs:
    batch_size: 256
    shuffle: true
    num_workers: 12
    drop_last: true
    pin_memory: true

  scheduler: "torch.optim.lr_scheduler.CosineAnnealingLR(opt, len(train_ldr) * epochs + 1)"
  exec_str: 'nn.utils.clip_grad_value_(model.parameters(), 0.5)'

  checkpoint_n: 4000

other_training_params:

  valid_dataloader_kwargs:
    batch_size: 256
    shuffle: false
    num_workers: 12
    drop_last: true
    pin_memory: true

  run_dir: "maftr-2023-11-23-d1.6_4"
  run_name: "gru1-2"

  save_metrics_n: 100
  evaluate_n: 1000

  metrics:
    x_metrics_items: 32
    x_metrics:
      x_l2: 'x_l2'

    y_metrics:
      y_l2: 'y_l2'


loss_func: 'stress_MSELoss'
loss_func_kwargs:
  y_ratio: 0.5
  x_grad_scale: 30.  # empirically similar
