tasks: rcpl.tasks.processing.*
uses: "{CONFIGS_DIR}/dataset/2023-08-27.experiment.yaml"

architecture: TransformerNet
model_parameters:
  d_model: 32
  in_dim: 1
  enc_dim: 31
  nhead: 2
  num_layers: 2
  str_len: 601
  outs: 11
  embedding: null

# training_params:
optim: 'AdamW'
optim_kwargs:
  lr: 0.001
  betas: [0.9, 0.99]
  eps: .00000001
  weight_decay: 0.01
epochs: 1
scheduler: "torch.optim.lr_scheduler.CosineAnnealingLR(opt, len(train_ldr) * epochs + 1)"
exec_str: 'nn.utils.clip_grad_value_(net.parameters(), 0.5)'
validate_batch_n: 100

# dataloader_params:
batch_size: 64
shuffle: True
num_workers: 12
drop_last: True

#
do_compile: false
run_name: "transformer"


x_metrics:
  x_l2: 'partial(metrics.x_l, p=2)'
  x_collect: 'metrics.x_collect'

y_metrics:
  y_l2: 'partial(metrics.y_l, p=2)'

deque_x_metrics:
  x_l1: 'partial(metrics.x_l, p=1)'
  x_l2: 'partial(metrics.x_l, p=2)'

deque_y_metrics:
  y_l2: 'partial(metrics.y_l, p=2)'

