tasks: rcpl.tasks.processing.*
uses: "{CONFIGS_DIR}/dataset/maf/2023-08-27.d1.2_4.maf2_4.yaml"

architecture: TransformerNet
takes_max_length: 603
takes_epsp: false
model_parameters:
  d_model: 32
  in_dim: 1
  enc_dim: 31
  nhead: 2
  num_layers: 4
  str_len: 603
  outs: 11
  embedding: null

loss_func: 'epsp'
loss_func_kwargs:
  y_ratio: 0.0
  x_grad_scale: 30.  # empirically similar

# training_params:
optim: 'AdamW'
optim_kwargs:
  lr: 0.001
  betas: [0.9, 0.99]
  eps: .00000001
  weight_decay: 0.01
epochs: 10
scheduler: "torch.optim.lr_scheduler.CosineAnnealingLR(opt, len(train_ldr) * epochs + 1)"
exec_str: 'nn.utils.clip_grad_value_(net.parameters(), 0.5)'
save_metrics_n: 100
evaluate_n: 300
checkpoint_n: 2000

# dataloader_params:
batch_size: 128
shuffle: true
num_workers: 12
drop_last: true

valid_batch_size: 256
do_compile: false
run_dir: "standard"
run_name: "tr4-1"


x_metrics:
  x_l2: 'metrics.x_l2'

y_metrics:
  y_l2: 'metrics.y_l2'
