tasks: rcpl.tasks.processing.*
uses: "{CONFIGS_DIR}/dataset/maf/2023-11-23.d1.maf2_4.yaml"


model:
  class: rcpl.models.fc.FC
  kwargs:
    inputs: 681
    layers: [512, 256, 128]
    outputs: 11
    in_channels: 1
    batchnorm: true

takes_max_length: 681
takes_channels: ['stress']
do_compile: true
is_trainable: true
prediction_is_scaled: true
# chosen_checkpoint: 199


persistent_training_params:
  epochs: 10

  optim: 'AdamW'
  optim_kwargs:
    lr: 0.001
    weight_decay: 0.01

  dataloader_kwargs:
    batch_size: 256
    shuffle: true
    num_workers: 12
    drop_last: true
    pin_memory: true

  scheduler: "torch.optim.lr_scheduler.CosineAnnealingLR(opt, len(train_ldr) * epochs + 1)"
  exec_str: 'nn.utils.clip_grad_value_(model.parameters(), 0.5)'

  checkpoint_n: 4000

other_training_params:

  valid_dataloader_kwargs:
    batch_size: 256
    shuffle: false
    num_workers: 12
    drop_last: true
    pin_memory: true

  run_dir: "maf-2023-11-23-d1"
  run_name: "fc1-1"

  save_metrics_n: 100
  evaluate_n: 1000

  metrics:
    x_metrics_items: 32
    x_metrics:
      x_l2: 'x_l2'

    y_metrics:
      y_l2: 'y_l2'
